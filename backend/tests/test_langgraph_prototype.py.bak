"""
Tests for the LangGraph workflow implementation.

Phase 1 tests: Intake, entity resolution, synthesis nodes
Phase 2 tests: Triage, conditional routing, parallel branch state merge
Phase 3 tests: Direct KG and Cold-Start real implementations

Run with: uv run pytest tests/test_langgraph_prototype.py -v
"""

import pytest
import asyncio
from unittest.mock import AsyncMock, patch, MagicMock

from src.kestrel_backend.graph.builder import build_discovery_graph, route_after_triage
from src.kestrel_backend.graph.state import (
    DiscoveryState, EntityResolution, NoveltyScore, Finding,
    DiseaseAssociation, PathwayMembership, InferredAssociation, AnalogueEntity
)
from src.kestrel_backend.graph.nodes import (
    intake, entity_resolution, triage, direct_kg, cold_start, synthesis
)


# =============================================================================
# Phase 1 Tests: Intake Node
# =============================================================================

class TestIntakeNode:
    """Tests for the intake node's parsing and detection logic."""

    @pytest.mark.asyncio
    async def test_discovery_mode_with_trigger_phrase(self):
        """Discovery triggers should be detected."""
        state: DiscoveryState = {
            "raw_query": "Analyze the relationship between glucose and insulin resistance"
        }
        result = await intake.run(state)
        assert result["query_type"] == "discovery"

    @pytest.mark.asyncio
    async def test_discovery_mode_with_multiple_entities(self):
        """Multiple entities should trigger discovery mode."""
        state: DiscoveryState = {
            "raw_query": "What do glucose, fructose, and mannose have in common?"
        }
        result = await intake.run(state)
        assert result["query_type"] == "discovery"
        assert len(result["raw_entities"]) >= 3

    @pytest.mark.asyncio
    async def test_retrieval_mode_simple_query(self):
        """Simple questions should be retrieval mode."""
        state: DiscoveryState = {
            "raw_query": "What is glucose?"
        }
        result = await intake.run(state)
        assert result["query_type"] == "retrieval"

    @pytest.mark.asyncio
    async def test_entity_extraction_comma_list(self):
        """Comma-separated entities should be extracted."""
        state: DiscoveryState = {
            "raw_query": "Analyze these metabolites: glucose, fructose, mannose"
        }
        result = await intake.run(state)
        entities_lower = [e.lower() for e in result["raw_entities"]]
        assert "glucose" in entities_lower or any("gluc" in e for e in entities_lower)

    @pytest.mark.asyncio
    async def test_longitudinal_detection(self):
        """Longitudinal study keywords should be detected."""
        state: DiscoveryState = {
            "raw_query": "Analyze the 5-year longitudinal OGTT study data for converters"
        }
        result = await intake.run(state)
        assert result["is_longitudinal"] is True
        assert result["duration_years"] == 5


# =============================================================================
# Phase 1 Tests: Entity Resolution Node
# =============================================================================

class TestEntityResolutionNode:
    """Tests for the entity resolution node with mocked SDK."""

    @pytest.mark.asyncio
    async def test_empty_entities(self):
        """Empty entity list should return empty results."""
        state: DiscoveryState = {
            "raw_entities": []
        }
        result = await entity_resolution.run(state)
        assert result["resolved_entities"] == []
        assert result["errors"] == []

    @pytest.mark.asyncio
    async def test_resolution_result_parsing(self):
        """Test JSON parsing from LLM response."""
        json_response = '{"curie": "CHEBI:17234", "name": "D-glucose", "category": "biolink:ChemicalEntity", "confidence": 0.95}'
        result = entity_resolution.parse_resolution_result("glucose", json_response)
        assert result.curie == "CHEBI:17234"
        assert result.resolved_name == "D-glucose"
        assert result.method == "exact"

    @pytest.mark.asyncio
    async def test_resolution_failure_handling(self):
        """Failed resolution should return method='failed'."""
        json_response = '{"curie": null, "name": null, "category": null, "confidence": 0.0}'
        result = entity_resolution.parse_resolution_result("unknownentity", json_response)
        assert result.method == "failed"
        assert result.curie is None

    @pytest.mark.asyncio
    async def test_batch_chunking(self):
        """Test that entities are chunked correctly."""
        items = list(range(15))
        chunks = entity_resolution.chunk(items, 6)
        assert len(chunks) == 3
        assert len(chunks[0]) == 6
        assert len(chunks[1]) == 6
        assert len(chunks[2]) == 3


# =============================================================================
# Phase 1 Tests: Synthesis Node
# =============================================================================

class TestSynthesisNode:
    """Tests for the synthesis node's report generation."""

    @pytest.mark.asyncio
    async def test_empty_entities_report(self):
        """Report should handle empty entity list."""
        state: DiscoveryState = {
            "raw_query": "test query",
            "query_type": "discovery",
            "resolved_entities": [],
        }
        result = await synthesis.run(state)
        assert "No entities were provided" in result["synthesis_report"]

    @pytest.mark.asyncio
    async def test_successful_resolution_report(self):
        """Report should include resolved entity details."""
        state: DiscoveryState = {
            "raw_query": "Analyze glucose",
            "query_type": "discovery",
            "resolved_entities": [
                EntityResolution(
                    raw_name="glucose",
                    curie="CHEBI:17234",
                    resolved_name="D-glucose",
                    category="biolink:ChemicalEntity",
                    confidence=0.95,
                    method="exact",
                )
            ],
        }
        result = await synthesis.run(state)
        report = result["synthesis_report"]
        assert "CHEBI:17234" in report
        assert "D-glucose" in report
        assert "1/1" in report  # success count

    @pytest.mark.asyncio
    async def test_report_includes_novelty_scores(self):
        """Report should include novelty classification."""
        state: DiscoveryState = {
            "raw_query": "Analyze glucose",
            "query_type": "discovery",
            "resolved_entities": [
                EntityResolution(
                    raw_name="glucose",
                    curie="CHEBI:17234",
                    resolved_name="D-glucose",
                    category="biolink:ChemicalEntity",
                    confidence=0.95,
                    method="exact",
                )
            ],
            "novelty_scores": [
                NoveltyScore(
                    curie="CHEBI:17234",
                    raw_name="glucose",
                    edge_count=500,
                    classification="well_characterized",
                )
            ],
        }
        result = await synthesis.run(state)
        report = result["synthesis_report"]
        assert "Well-Characterized" in report
        assert "500 edges" in report

    @pytest.mark.asyncio
    async def test_report_includes_findings(self):
        """Report should include findings from analysis branches."""
        state: DiscoveryState = {
            "raw_query": "Analyze glucose and novelty",
            "query_type": "discovery",
            "resolved_entities": [],
            "direct_findings": [
                Finding(entity="CHEBI:17234", claim="Test finding from direct KG", tier=1, source="direct_kg")
            ],
            "cold_start_findings": [
                Finding(entity="unknown", claim="Test finding from cold start", tier=3, source="cold_start")
            ],
        }
        result = await synthesis.run(state)
        report = result["synthesis_report"]
        assert "Tier 1" in report
        assert "Tier 3" in report
        assert "Test finding from direct KG" in report
        assert "Test finding from cold start" in report


# =============================================================================
# Phase 2 Tests: Triage Node
# =============================================================================

class TestTriageNode:
    """Tests for the triage node's novelty scoring and classification."""

    @pytest.mark.asyncio
    async def test_classify_by_edge_count(self):
        """Test classification thresholds."""
        assert triage.classify_by_edge_count(500) == "well_characterized"
        assert triage.classify_by_edge_count(200) == "well_characterized"
        assert triage.classify_by_edge_count(100) == "moderate"
        assert triage.classify_by_edge_count(20) == "moderate"
        assert triage.classify_by_edge_count(10) == "sparse"
        assert triage.classify_by_edge_count(1) == "sparse"
        assert triage.classify_by_edge_count(0) == "cold_start"

    @pytest.mark.asyncio
    async def test_parse_edge_count_result(self):
        """Test JSON parsing from edge count response."""
        json_response = '{"curie": "CHEBI:17234", "edge_count": 250}'
        result = triage.parse_edge_count_result("CHEBI:17234", "glucose", json_response)
        assert result.curie == "CHEBI:17234"
        assert result.edge_count == 250
        assert result.classification == "well_characterized"

    @pytest.mark.asyncio
    async def test_empty_resolved_entities(self):
        """Empty resolved entities should return empty scores."""
        state: DiscoveryState = {"resolved_entities": []}
        result = await triage.run(state)
        assert result["novelty_scores"] == []
        assert result["well_characterized_curies"] == []

    @pytest.mark.asyncio
    async def test_failed_entities_go_to_cold_start(self):
        """Failed resolutions should be routed to cold_start."""
        state: DiscoveryState = {
            "resolved_entities": [
                EntityResolution(
                    raw_name="unknown_entity",
                    curie=None,
                    method="failed",
                    confidence=0.0,
                )
            ]
        }
        result = await triage.run(state)
        assert "unknown_entity" in result["cold_start_curies"]

    @pytest.mark.asyncio
    async def test_triage_with_mocked_sdk(self):
        """Test full triage with mocked edge counting."""
        mock_score = NoveltyScore(
            curie="CHEBI:17234",
            raw_name="glucose",
            edge_count=300,
            classification="well_characterized",
        )

        with patch.object(triage, 'count_edges_single', return_value=mock_score):
            state: DiscoveryState = {
                "resolved_entities": [
                    EntityResolution(
                        raw_name="glucose",
                        curie="CHEBI:17234",
                        resolved_name="D-glucose",
                        category="biolink:ChemicalEntity",
                        confidence=0.95,
                        method="exact",
                    )
                ]
            }
            result = await triage.run(state)
            assert len(result["novelty_scores"]) == 1
            assert "CHEBI:17234" in result["well_characterized_curies"]


# =============================================================================
# Phase 2 Tests: Routing Logic
# =============================================================================

class TestRoutingLogic:
    """Tests for the conditional routing function."""

    def test_route_both_branches(self):
        """Mixed entities should route to both branches."""
        state: DiscoveryState = {
            "well_characterized_curies": ["CHEBI:17234"],
            "moderate_curies": [],
            "sparse_curies": ["GENE:12345"],
            "cold_start_curies": [],
        }
        result = route_after_triage(state)
        assert isinstance(result, list)
        assert "direct_kg" in result
        assert "cold_start" in result

    def test_route_direct_only(self):
        """Only well-characterized should route to direct_kg."""
        state: DiscoveryState = {
            "well_characterized_curies": ["CHEBI:17234"],
            "moderate_curies": ["CHEBI:56789"],
            "sparse_curies": [],
            "cold_start_curies": [],
        }
        result = route_after_triage(state)
        assert result == "direct_kg"

    def test_route_cold_start_only(self):
        """Only sparse should route to cold_start."""
        state: DiscoveryState = {
            "well_characterized_curies": [],
            "moderate_curies": [],
            "sparse_curies": ["GENE:12345"],
            "cold_start_curies": ["unknown"],
        }
        result = route_after_triage(state)
        assert result == "cold_start"

    def test_route_to_synthesis_when_empty(self):
        """No entities should skip to synthesis."""
        state: DiscoveryState = {
            "well_characterized_curies": [],
            "moderate_curies": [],
            "sparse_curies": [],
            "cold_start_curies": [],
        }
        result = route_after_triage(state)
        assert result == "synthesis"


# =============================================================================
# Phase 3 Tests: Direct KG Node
# =============================================================================

class TestDirectKGNode:
    """Tests for the direct_kg node's real implementation."""

    @pytest.mark.asyncio
    async def test_empty_entities(self):
        """Empty entity list should return empty results."""
        state: DiscoveryState = {
            "well_characterized_curies": [],
            "moderate_curies": [],
        }
        result = await direct_kg.run(state)
        assert result["direct_findings"] == []
        assert result["disease_associations"] == []
        assert result["pathway_memberships"] == []

    @pytest.mark.asyncio
    async def test_parse_direct_kg_result_with_diseases(self):
        """Test parsing disease associations from JSON response."""
        json_response = '''```json
{
  "diseases": [
    {"curie": "MONDO:0005148", "name": "Type 2 Diabetes", "predicate": "biolink:gene_associated_with_condition", "source": "GWAS Catalog", "pmids": ["PMID:12345"], "is_hub": false}
  ],
  "pathways": [],
  "interactions": [],
  "hub_flags": []
}
```'''
        diseases, pathways, findings, hub_flags = direct_kg.parse_direct_kg_result(
            "CHEBI:17234", "glucose", json_response
        )
        assert len(diseases) == 1
        assert diseases[0].disease_name == "Type 2 Diabetes"
        assert diseases[0].evidence_type == "gwas"
        assert len(findings) == 1
        assert findings[0].tier == 1

    @pytest.mark.asyncio
    async def test_parse_direct_kg_result_with_pathways(self):
        """Test parsing pathway memberships from JSON response."""
        json_response = '''{
  "diseases": [],
  "pathways": [
    {"curie": "GO:0006094", "name": "Gluconeogenesis", "predicate": "biolink:participates_in", "source": "Reactome"}
  ],
  "interactions": [],
  "hub_flags": []
}'''
        diseases, pathways, findings, hub_flags = direct_kg.parse_direct_kg_result(
            "CHEBI:17234", "glucose", json_response
        )
        assert len(pathways) == 1
        assert pathways[0].pathway_name == "Gluconeogenesis"
        assert len(findings) == 1
        assert "participates in" in findings[0].claim

    @pytest.mark.asyncio
    async def test_parse_direct_kg_result_with_hub_flags(self):
        """Test hub bias detection."""
        json_response = '''{
  "diseases": [
    {"curie": "MONDO:0005148", "name": "Diabetes", "predicate": "related_to", "source": "unknown", "is_hub": true}
  ],
  "pathways": [],
  "interactions": [],
  "hub_flags": ["MONDO:0005148", "GO:0008150"]
}'''
        diseases, pathways, findings, hub_flags = direct_kg.parse_direct_kg_result(
            "CHEBI:17234", "glucose", json_response
        )
        assert "MONDO:0005148" in hub_flags
        assert "GO:0008150" in hub_flags

    @pytest.mark.asyncio
    async def test_parse_direct_kg_result_fallback_on_invalid_json(self):
        """Test graceful fallback on invalid JSON."""
        invalid_response = "This is not JSON at all, just some text"
        diseases, pathways, findings, hub_flags = direct_kg.parse_direct_kg_result(
            "CHEBI:17234", "glucose", invalid_response
        )
        assert diseases == []
        assert pathways == []
        assert findings == []

    @pytest.mark.asyncio
    async def test_direct_kg_with_sdk_unavailable(self):
        """Test graceful handling when SDK is not available."""
        with patch.object(direct_kg, 'HAS_SDK', False):
            state: DiscoveryState = {
                "well_characterized_curies": ["CHEBI:17234"],
                "moderate_curies": [],
                "novelty_scores": [NoveltyScore(curie="CHEBI:17234", raw_name="glucose", edge_count=300, classification="well_characterized")],
            }
            result = await direct_kg.run(state)
            assert len(result["direct_findings"]) == 1
            assert "SDK unavailable" in result["direct_findings"][0].claim


# =============================================================================
# Phase 3 Tests: Cold-Start Node
# =============================================================================

class TestColdStartNode:
    """Tests for the cold_start node's real implementation."""

    @pytest.mark.asyncio
    async def test_empty_entities(self):
        """Empty entity list should return empty results."""
        state: DiscoveryState = {
            "sparse_curies": [],
            "cold_start_curies": [],
        }
        result = await cold_start.run(state)
        assert result["cold_start_findings"] == []
        assert result["inferred_associations"] == []
        assert result["analogues_found"] == []

    @pytest.mark.asyncio
    async def test_parse_cold_start_result_with_analogues(self):
        """Test parsing analogues from JSON response."""
        json_response = '''```json
{
  "analogues": [
    {"curie": "CHEBI:17234", "name": "D-glucose", "similarity": 0.85, "category": "biolink:ChemicalEntity"}
  ],
  "inferences": []
}
```'''
        analogues, inferences, findings = cold_start.parse_cold_start_result(
            "CHEBI:99999", "unknown_metabolite", 0, json_response
        )
        assert len(analogues) == 1
        assert analogues[0].name == "D-glucose"
        assert analogues[0].similarity == 0.85
        # Should generate a finding about the analogues
        assert len(findings) >= 1

    @pytest.mark.asyncio
    async def test_parse_cold_start_result_with_inferences(self):
        """Test parsing inferred associations from JSON response."""
        json_response = '''{
  "analogues": [
    {"curie": "CHEBI:17234", "name": "D-glucose", "similarity": 0.85}
  ],
  "inferences": [
    {
      "target_curie": "MONDO:0005148",
      "target_name": "Type 2 Diabetes",
      "predicate": "biolink:may_be_associated_with",
      "logic_chain": "X is similar to glucose (0.85). Glucose is associated with T2D. X may also be associated.",
      "supporting_analogues": 3,
      "confidence": "low",
      "validation_step": "Test X in diabetes cell model"
    }
  ]
}'''
        analogues, inferences, findings = cold_start.parse_cold_start_result(
            "CHEBI:99999", "unknown_metabolite", 0, json_response
        )
        assert len(inferences) == 1
        assert inferences[0].target_name == "Type 2 Diabetes"
        assert inferences[0].supporting_analogues == 3
        assert "glucose" in inferences[0].logic_chain.lower()
        assert len(findings) >= 1
        assert findings[0].tier == 3

    @pytest.mark.asyncio
    async def test_cold_start_findings_are_tier_3(self):
        """All cold-start findings must be Tier 3."""
        json_response = '''{
  "analogues": [],
  "inferences": [
    {
      "target_curie": "MONDO:0005148",
      "target_name": "Disease X",
      "predicate": "related_to",
      "logic_chain": "Inferred via similarity",
      "supporting_analogues": 1,
      "confidence": "low",
      "validation_step": "Check experimentally"
    }
  ]
}'''
        analogues, inferences, findings = cold_start.parse_cold_start_result(
            "CHEBI:99999", "unknown", 0, json_response
        )
        for f in findings:
            assert f.tier == 3, "Cold-start findings must be Tier 3"

    @pytest.mark.asyncio
    async def test_cold_start_includes_logic_chains(self):
        """Cold-start findings should include logic chains."""
        json_response = '''{
  "analogues": [],
  "inferences": [
    {
      "target_curie": "MONDO:0005148",
      "target_name": "Disease X",
      "predicate": "related_to",
      "logic_chain": "X similar to Y, Y connected to Z, therefore X may connect to Z",
      "supporting_analogues": 2,
      "confidence": "low",
      "validation_step": "Test experimentally"
    }
  ]
}'''
        analogues, inferences, findings = cold_start.parse_cold_start_result(
            "CHEBI:99999", "unknown", 0, json_response
        )
        assert len(findings) >= 1
        assert findings[0].logic_chain is not None
        assert "similar" in findings[0].logic_chain.lower()

    @pytest.mark.asyncio
    async def test_cold_start_with_sdk_unavailable(self):
        """Test graceful handling when SDK is not available."""
        with patch.object(cold_start, 'HAS_SDK', False):
            state: DiscoveryState = {
                "sparse_curies": ["GENE:99999"],
                "cold_start_curies": [],
                "novelty_scores": [NoveltyScore(curie="GENE:99999", raw_name="novel_gene", edge_count=5, classification="sparse")],
            }
            result = await cold_start.run(state)
            assert len(result["cold_start_findings"]) == 1
            assert "SDK unavailable" in result["cold_start_findings"][0].claim


# =============================================================================
# Phase 3 Tests: Synthesis with Structured Data
# =============================================================================

class TestSynthesisPhase3:
    """Tests for synthesis node with Phase 3 structured data."""

    @pytest.mark.asyncio
    async def test_report_includes_disease_associations(self):
        """Report should format disease associations with evidence types."""
        state: DiscoveryState = {
            "raw_query": "Analyze glucose",
            "query_type": "discovery",
            "resolved_entities": [],
            "disease_associations": [
                DiseaseAssociation(
                    entity_curie="CHEBI:17234",
                    disease_curie="MONDO:0005148",
                    disease_name="Type 2 Diabetes",
                    predicate="biolink:gene_associated_with_condition",
                    source="GWAS Catalog",
                    pmids=["PMID:12345"],
                    evidence_type="gwas",
                )
            ],
        }
        result = await synthesis.run(state)
        report = result["synthesis_report"]
        assert "Disease Associations" in report
        assert "Type 2 Diabetes" in report
        assert "GWAS" in report

    @pytest.mark.asyncio
    async def test_report_includes_pathway_memberships(self):
        """Report should format pathway memberships."""
        state: DiscoveryState = {
            "raw_query": "Analyze glucose",
            "query_type": "discovery",
            "resolved_entities": [],
            "pathway_memberships": [
                PathwayMembership(
                    entity_curie="CHEBI:17234",
                    pathway_curie="GO:0006094",
                    pathway_name="Gluconeogenesis",
                    predicate="biolink:participates_in",
                    source="Reactome",
                )
            ],
        }
        result = await synthesis.run(state)
        report = result["synthesis_report"]
        assert "Pathway" in report or "Biological Process" in report
        assert "Gluconeogenesis" in report

    @pytest.mark.asyncio
    async def test_report_includes_inferred_associations(self):
        """Report should format inferred associations with logic chains."""
        state: DiscoveryState = {
            "raw_query": "Analyze unknown metabolite",
            "query_type": "discovery",
            "resolved_entities": [],
            "inferred_associations": [
                InferredAssociation(
                    source_entity="CHEBI:99999",
                    target_curie="MONDO:0005148",
                    target_name="Type 2 Diabetes",
                    predicate="biolink:may_be_associated_with",
                    logic_chain="X similar to glucose, glucose associated with T2D",
                    supporting_analogues=3,
                    confidence="low",
                    validation_step="Test in cell model",
                )
            ],
            "analogues_found": [
                AnalogueEntity(curie="CHEBI:17234", name="D-glucose", similarity=0.85, category="biolink:ChemicalEntity")
            ],
        }
        result = await synthesis.run(state)
        report = result["synthesis_report"]
        assert "Inferred" in report
        assert "Tier 3" in report or "Speculative" in report
        assert "logic" in report.lower() or "Logic" in report

    @pytest.mark.asyncio
    async def test_report_includes_hub_warnings(self):
        """Report should include hub bias warnings."""
        state: DiscoveryState = {
            "raw_query": "Analyze glucose",
            "query_type": "discovery",
            "resolved_entities": [],
            "hub_flags": ["GO:0008150", "MONDO:0000001"],
        }
        result = await synthesis.run(state)
        report = result["synthesis_report"]
        assert "Hub" in report or "hub" in report
        assert "GO:0008150" in report


# =============================================================================
# Phase 2 Tests: Parallel Branch State Merge (with proper mocking)
# =============================================================================

class TestParallelBranches:
    """Tests for parallel branch state merging."""

    @pytest.mark.asyncio
    async def test_parallel_state_merge(self):
        """Critical: verify operator.add merges findings from parallel branches."""
        # Create mock resolutions and scores for mixed routing
        mock_resolution_well = EntityResolution(
            raw_name="glucose",
            curie="CHEBI:17234",
            resolved_name="D-glucose",
            category="biolink:ChemicalEntity",
            confidence=0.95,
            method="exact",
        )
        mock_resolution_sparse = EntityResolution(
            raw_name="novelty",
            curie="GENE:99999",
            resolved_name="Novel Gene",
            category="biolink:Gene",
            confidence=0.8,
            method="fuzzy",
        )

        # Mock edge counting to return well-characterized and sparse
        async def mock_count_edges(entity):
            if entity.curie == "CHEBI:17234":
                return NoveltyScore(
                    curie="CHEBI:17234",
                    raw_name="glucose",
                    edge_count=500,
                    classification="well_characterized",
                )
            else:
                return NoveltyScore(
                    curie="GENE:99999",
                    raw_name="novelty",
                    edge_count=5,
                    classification="sparse",
                )

        with patch.object(entity_resolution, 'resolve_single_entity') as mock_resolve:
            # Return different resolutions based on input
            async def resolve_side_effect(entity):
                if "glucose" in entity.lower():
                    return mock_resolution_well
                else:
                    return mock_resolution_sparse
            mock_resolve.side_effect = resolve_side_effect

            with patch.object(triage, 'count_edges_single', side_effect=mock_count_edges):
                # CRITICAL: Also mock direct_kg and cold_start HAS_SDK flags
                with patch.object(direct_kg, 'HAS_SDK', False):
                    with patch.object(cold_start, 'HAS_SDK', False):
                        graph = build_discovery_graph()
                        result = await graph.ainvoke({
                            "raw_query": "Analyze: glucose, novelty"
                        })

                        # Verify both branches produced findings
                        direct_findings = result.get("direct_findings", [])
                        cold_start_findings = result.get("cold_start_findings", [])

                        # Both branches should have findings
                        assert len(direct_findings) > 0, "direct_kg branch should produce findings"
                        assert len(cold_start_findings) > 0, "cold_start branch should produce findings"

                        # Synthesis should include all findings
                        report = result.get("synthesis_report", "")
                        assert "direct_kg" in report or "Tier 1" in report
                        assert "cold_start" in report or "Tier 3" in report


# =============================================================================
# End-to-End Tests
# =============================================================================

class TestEndToEnd:
    """End-to-end tests for the complete workflow."""

    @pytest.mark.asyncio
    async def test_graph_builds_successfully(self):
        """Graph should compile without errors."""
        graph = build_discovery_graph()
        assert graph is not None

    @pytest.mark.asyncio
    async def test_workflow_with_mocked_resolution(self):
        """Complete workflow with mocked entity resolution."""
        mock_resolution = EntityResolution(
            raw_name="glucose",
            curie="CHEBI:17234",
            resolved_name="D-glucose",
            category="biolink:ChemicalEntity",
            confidence=0.95,
            method="exact",
        )
        mock_score = NoveltyScore(
            curie="CHEBI:17234",
            raw_name="glucose",
            edge_count=300,
            classification="well_characterized",
        )

        with patch.object(entity_resolution, 'resolve_single_entity', return_value=mock_resolution):
            with patch.object(triage, 'count_edges_single', return_value=mock_score):
                with patch.object(direct_kg, 'HAS_SDK', False):
                    with patch.object(cold_start, 'HAS_SDK', False):
                        graph = build_discovery_graph()
                        result = await graph.ainvoke({
                            "raw_query": "Analyze these metabolites: glucose, fructose"
                        })

                        assert result["query_type"] == "discovery"
                        assert "synthesis_report" in result
                        assert len(result.get("resolved_entities", [])) > 0
                        assert len(result.get("novelty_scores", [])) > 0

    @pytest.mark.asyncio
    async def test_workflow_handles_sdk_unavailable(self):
        """Workflow should handle missing SDK gracefully."""
        with patch.object(entity_resolution, 'HAS_SDK', False):
            with patch.object(triage, 'HAS_SDK', False):
                with patch.object(direct_kg, 'HAS_SDK', False):
                    with patch.object(cold_start, 'HAS_SDK', False):
                        graph = build_discovery_graph()
                        result = await graph.ainvoke({
                            "raw_query": "What is glucose?"
                        })

                        # Should still complete without crashing
                        assert "synthesis_report" in result

    @pytest.mark.asyncio
    async def test_full_pipeline_with_triage(self):
        """intake -> entity_resolution -> triage -> [branches] -> synthesis"""
        mock_resolution = EntityResolution(
            raw_name="glucose",
            curie="CHEBI:17234",
            resolved_name="D-glucose",
            category="biolink:ChemicalEntity",
            confidence=0.95,
            method="exact",
        )
        mock_score = NoveltyScore(
            curie="CHEBI:17234",
            raw_name="glucose",
            edge_count=300,
            classification="well_characterized",
        )

        with patch.object(entity_resolution, 'resolve_single_entity', return_value=mock_resolution):
            with patch.object(triage, 'count_edges_single', return_value=mock_score):
                with patch.object(direct_kg, 'HAS_SDK', False):
                    with patch.object(cold_start, 'HAS_SDK', False):
                        graph = build_discovery_graph()
                        result = await graph.ainvoke({
                            "raw_query": "Analyze: glucose, KIF6, NLGN1"
                        })

                        # Verify triage populated
                        assert result.get("novelty_scores") is not None
                        assert result.get("synthesis_report") is not None

                        # Report should include classification
                        report = result["synthesis_report"]
                        assert "Well-Characterized" in report or "Tier" in report


# =============================================================================
# Integration Tests (require Kestrel API)
# =============================================================================

@pytest.mark.integration
class TestIntegration:
    """Integration tests requiring actual Kestrel API connectivity."""

    @pytest.mark.asyncio
    async def test_direct_kg_with_real_api(self):
        """Test direct_kg with actual Kestrel API calls."""
        # Skip if SDK not available
        if not direct_kg.HAS_SDK:
            pytest.skip("Claude Agent SDK not available")

        state: DiscoveryState = {
            "well_characterized_curies": ["CHEBI:17234"],  # glucose
            "moderate_curies": [],
            "novelty_scores": [NoveltyScore(curie="CHEBI:17234", raw_name="glucose", edge_count=300, classification="well_characterized")],
        }
        result = await direct_kg.run(state)

        # Should have real findings, not just "pending" stubs
        findings = result.get("direct_findings", [])
        assert len(findings) > 0
        # At least one finding should have real content (not "pending")
        assert any("pending" not in f.claim.lower() for f in findings)

    @pytest.mark.asyncio
    async def test_full_pipeline_with_real_analysis(self):
        """End-to-end with actual KG queries."""
        # Skip if SDK not available
        if not entity_resolution.HAS_SDK:
            pytest.skip("Claude Agent SDK not available")

        graph = build_discovery_graph()
        result = await graph.ainvoke({
            "raw_query": "Analyze: glucose"
        })

        findings = result.get("direct_findings", []) + result.get("cold_start_findings", [])
        # Should have at least one non-stub finding
        assert any("pending" not in f.claim.lower() and "unavailable" not in f.claim.lower() for f in findings)


# Run tests with: uv run pytest tests/test_langgraph_prototype.py -v
if __name__ == "__main__":
    pytest.main([__file__, "-v"])
